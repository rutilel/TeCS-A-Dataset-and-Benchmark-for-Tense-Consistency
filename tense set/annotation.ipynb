{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import xlwt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\model\\\\prediction.txt','r')\n",
    "alllines=f.readlines()\n",
    "f.close()\n",
    "f=open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\model\\\\prediction.txt','w+')\n",
    "for eachline in alllines:\n",
    "    a=re.sub('shall','will',eachline)\n",
    "    b=re.sub('Shall','Will',a)\n",
    "    f.writelines(b)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TenseSegmentModel:\n",
    "    def __init__(self, token, lemma, tag):\n",
    "        self.token = token\n",
    "        self.lemma = lemma\n",
    "        self.tag = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TenseModel:\n",
    "    def __init__(self, tense_segments: list):\n",
    "        self.segments = tense_segments\n",
    "        self.tense = None\n",
    "        self.find_tense(self.get_passive_pattern())\n",
    "        if self.tense is None:\n",
    "            self.find_tense(self.get_normal_pattern())\n",
    "        #if self.tense is None:\n",
    "            #self.tense = \"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_passive_pattern():\n",
    "        return {\n",
    "            'Present': [{'be': ['VBZ', 'VBP']}, {'_': ['VBN']}],\n",
    "            'Modal1': [{'_all_modalpre_': ['MD']}, {'be': ['VB']}, {'_': ['VBN']}],\n",
    "            'PresentContinuous': [{'be': ['VBZ', 'VBP']}, {'be': ['VBG']}, {'_': ['VBN']}],\n",
    "            'Past': [{'be': ['VBD']}, {'_': ['VBN']}],\n",
    "            'PastContinuous': [{'be': ['VBD']}, {'be': ['VBG']}, {'_': ['VBN']}],\n",
    "            'Modal2': [{'_all_modalpas_': ['MD']}, {'be': ['VB']}, {'_': ['VBN']}],\n",
    "            'PrePerfect': [{'have': ['VBZ', 'VBP']}, {'be': ['VBN']}, {'_': ['VBN']}],\n",
    "            'PasPerfect': [{'have': ['VBD']}, {'be': ['VBN']}, {'_': ['VBN']}],\n",
    "            'Future': [{'will': ['MD']}, {'be': ['VB']}, {'_': ['VBN']}],\n",
    "            'FutureContinuous': [{'will': ['MD']}, {'be': ['VB']}, {'be': ['VBG']}, {'_': ['VBN']}],\n",
    "            'PreSubjunctive': [{'_all_modalpas_': ['MD']}, {'be': ['VB']}, {'_': ['VBN']}],\n",
    "            'PasSubjunctive': [{'_all_modalpas_': ['MD']}, {'have': ['VB']}, {'be': ['VBN']}, {'_': ['VBN']}],\n",
    "            'Infinitive': [{'must': ['MD']}, {'be': ['VB']}, {'_': ['VBN']}],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_normal_pattern():\n",
    "        return {\n",
    "            #'Pasth': [{'had': ['VBN']}],\n",
    "            'Present': [{'_': ['VBZ', 'VBP', 'VB']}],\n",
    "            'Modal1': [{'_all_modalpre_': ['MD']}, {'_': ['VB']}], \n",
    "            'Modal2': [{'_all_modalpas_': ['MD']}, {'_': ['VB']}],\n",
    "            'PresentContinuous': [{'be': ['VBZ', 'VBP']}, {'_': ['VBG']}],\n",
    "            'Past': [{'_': ['VBD']}],\n",
    "            'PastContinuous': [{'be': ['VBD']}, {'_': ['VBG']}],\n",
    "            'PrePerfect': [{'have': ['VBZ', 'VBP']}, {'_': ['VBN']}],\n",
    "            'PrePerfectContinuous': [{'have': ['VBZ', 'VBP']}, {'be': ['VBN']}, {'_': ['VBG']}],\n",
    "            'PasPerfect': [{'have': ['VBD']}, {'_': ['VBN']}],\n",
    "            'PasPerfectContinuous': [{'have': ['VBD']}, {'be': ['VBN']}, {'_': ['VBG']}],\n",
    "            'FutPerfect': [{'will': ['MD']}, {'have': ['VB']}, {'_': ['VBN']}],\n",
    "            'FutPerfectContinuous': [{'will': ['MD']}, {'have': ['VB']}, {'be': ['VBN']}, {'_': ['VBG']}],\n",
    "            'Future': [{'will': ['MD']}, {'_': ['VB']}],\n",
    "            'FutureContinuous': [{'will': ['MD']}, {'be': ['VB']}, {'_': ['VBG']}],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_all_modalpre():\n",
    "        return ['can', 'may', 'shall', 'must']\n",
    "        #return ['can', 'may', 'must']\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_modalpas():\n",
    "        return ['could','might','should','would']\n",
    "\n",
    "    def find_tense(self, patterns):\n",
    "        for tense_name, tense_pattern in patterns.items():\n",
    "            if len(tense_pattern) != len(self.segments):\n",
    "                continue\n",
    "\n",
    "            for index, segment_pattern in enumerate(tense_pattern):\n",
    "                if len(self.segments) > index and self.segments[index] is not None:\n",
    "                    tense_segment = self.segments[index]\n",
    "                    if '_' in segment_pattern and len(self.segments) == index + 1:\n",
    "                        if tense_segment.tag in segment_pattern['_']:\n",
    "                            self.tense = tense_name\n",
    "                            return True\n",
    "                    if tense_segment.lemma in segment_pattern:\n",
    "                        if tense_segment.tag in segment_pattern[tense_segment.lemma]:\n",
    "                            if tense_segment.lemma in segment_pattern:\n",
    "                                continue\n",
    "\n",
    "                    elif tense_segment.lemma in self.get_all_modalpre():\n",
    "                        if '_all_modalpre_' in segment_pattern:\n",
    "                            continue\n",
    "                    elif tense_segment.lemma in self.get_all_modalpas():\n",
    "                        if '_all_modalpas_' in segment_pattern:\n",
    "                            continue\n",
    "                    elif tense_segment.lemma == 'have' and len(self.segments) == 1:\n",
    "                        self.tense = tense_name\n",
    "                        return True\n",
    "                    break\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTenseModel:\n",
    "    def __init__(self, tokens):\n",
    "        self._tokens = tokens\n",
    "\n",
    "    def parse(self):\n",
    "        tense_list = []\n",
    "\n",
    "        current_tense = []\n",
    "        increment_counter = 0\n",
    "        for token in self._tokens:\n",
    "            if token.pos_ in ('AUX', 'VERB'):\n",
    "                increment_counter += 1\n",
    "                tense_segment = TenseSegmentModel(token.text, token.lemma_, token.tag_)\n",
    "                current_tense.append(tense_segment)\n",
    "            elif increment_counter > 0:\n",
    "                increment_counter = 0\n",
    "                tense = TenseModel(current_tense)\n",
    "                tense_list.append(tense)\n",
    "                current_tense = []\n",
    "        return tense_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TenseParser:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def find_tenses(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        tense_list = []\n",
    "        # for token in doc:\n",
    "        #     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)\n",
    "        for sentence in doc.sents:\n",
    "            if len(sentence) <= 1:\n",
    "                continue\n",
    "            sentence_tense_model = SentenceTenseModel(sentence)\n",
    "            tense_list.append(sentence_tense_model.parse())\n",
    "        return tense_list\n",
    "\n",
    "    def find_tense_simple_form(self, text):\n",
    "        result = self.find_tenses(text)\n",
    "        return [[tense.tense for tense in sentence] for sentence in result]\n",
    "\n",
    "    def find_tense_simple_form_str(self, text):\n",
    "        result = self.find_tense_simple_form(text)\n",
    "        return '. '.join([''.join([str(tense) for tense in sentence]) for sentence in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\model\\\\prediction.txt','r',encoding='utf-8')\n",
    "tensep=open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\tensep.txt','w')\n",
    " \n",
    "lines=prediction.readlines()  \n",
    "prediction.close()\n",
    " \n",
    "for line in lines:\n",
    "    tense_parser = TenseParser()\n",
    "    print(tense_parser.find_tense_simple_form_str(line), file=tensep)\n",
    "    \n",
    "tensep.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\tensep.txt','r')\n",
    "alllines=f.readlines()\n",
    "f.close()\n",
    "f=open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\tensep.txt','w+')\n",
    "for eachline in alllines:\n",
    "    a=re.sub('PresentContinuous','Present',eachline)\n",
    "    b=re.sub('PastContinuous','Past',a)\n",
    "    c=re.sub('FutureContinuous','Future',b)\n",
    "    d=re.sub('PrePerfectContinuous','PrePerfect',c)\n",
    "    e=re.sub('PasPerfectContinuous','PasPerfect',d)\n",
    "    g=re.sub('FutPerfectContinuous','FutPerfect',e)\n",
    "    h=re.sub('Modal1','Modal',g)\n",
    "    i=re.sub('Modal2','Modal',h)\n",
    "    j=re.sub('PresentPresent','Present',i)  \n",
    "    k=re.sub('PresentPresent','Present',j)\n",
    "    final=re.sub('None','',k)\n",
    "    f.writelines(final)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 9, 14, 17, 22, 24, 32, 33, 36, 37, 38, 40, 41, 43, 45, 49, 50, 51, 53, 56, 60, 70, 77, 85, 88, 90, 91, 94, 103, 108, 109, 115, 117, 119, 121, 122, 123, 124, 125, 126, 128, 129, 131, 132, 134, 137, 139, 143, 144, 146, 147, 149, 150, 153, 160, 163, 164, 166, 168, 169, 171, 173, 174, 176, 177, 182, 183, 187, 189, 196, 198, 200, 202, 203, 207, 211, 212, 213, 217, 218, 219, 222, 225, 228, 233, 239, 241, 242, 244, 245, 252, 253, 255, 258, 259, 266, 268, 279, 282, 283, 284, 288, 289, 290, 291, 293, 295, 297, 299, 302, 307, 308, 309, 310, 311, 313, 315, 316, 319, 322, 323, 324, 328, 329, 330, 331, 332, 333, 335, 336, 338, 339, 342, 343, 344, 346, 347, 348, 349, 352, 353, 355, 357, 360, 361, 362, 363, 364, 368, 369, 370, 371, 372, 374, 375, 377, 378, 379, 382, 383, 386, 388, 391, 393, 395, 396, 398, 400, 401, 404, 405, 410, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 424, 426, 427, 428, 429, 430, 431, 432, 433, 435, 437, 438, 439, 440, 442, 443, 444, 447, 448, 455, 457, 459, 462, 463, 464, 471, 476, 477, 478, 479, 480, 481, 486, 488, 492, 493, 495, 496, 498, 503, 504, 506, 513, 514, 515, 516, 518, 519, 522, 524, 526, 528, 529, 531, 532, 537, 540, 541, 542, 543, 547, 548, 549, 552]\n"
     ]
    }
   ],
   "source": [
    "L=[]\n",
    "with open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\tenseref.txt') as f1, open('F:\\\\Y4\\\\NLP\\\\triage\\\\europarl\\\\result\\\\tensep.txt') as f2:\n",
    "    for lineno, (line1, line2) in enumerate(zip(f1, f2), 1):\n",
    "        if line1 != line2:\n",
    "            L.append(lineno)\n",
    "print(L)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.552536231884058\n"
     ]
    }
   ],
   "source": [
    "l=len(L)\n",
    "print(1-l/552)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tense]",
   "language": "python",
   "name": "conda-env-tense-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
